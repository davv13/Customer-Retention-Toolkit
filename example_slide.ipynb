{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Customer Retention Toolkit Demo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Welcome to our Customer Churn Prediction guide. Within the competitive subscription service industry, addressing customer churn is key to business longevity. Utilizing marketing analytics and machine learning, this project predicts churn from customer data and behavior. This guide outlines use cases like early risk detection and tailored retention campaigns, aiming to lower churn and boost customer contentment for enduring business growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Structure Overview\n",
    "\n",
    "- **api**: Contains the interface for interacting with the predictive model.\n",
    "- **db**: Database scripts, including the schema and SQL interactions.\n",
    "- **docs**: Documentation files, such as the Entity Relationship Diagram (ERD), usage instructions, roadmap, and use cases.\n",
    "- **logger**: Logging functionality to keep track of operations and errors.\n",
    "- **models**: The machine learning models and related workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "Steps to run the code:\n",
    "\n",
    "1. Create new env. (pythom -m venv venv)\n",
    "2. Install the requirements.txt in the env by.(pip install -r requirements.txt)\n",
    "3. Run the cells in example.ipynb\n",
    "4. When you reach the API part, start the api (python run.py)\n",
    "\n",
    "The following steps are for web usage of API:\n",
    "\n",
    "5. Then next of http://127.0.0.1:5000 add http://127.0.0.1:5000/docs and press enter.\n",
    "6. Press on the get_info, theb press on try it out and on the ID write any id from 1 to 3 and press execute.\n",
    "7. you will find the result in Response body. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from customer_retention_toolkit.db.schema import *\n",
    "from customer_retention_toolkit.db.sql_interactions import  SqlHandler\n",
    "from customer_retention_toolkit.logger import *\n",
    "from FillTables import *\n",
    "from customer_retention_toolkit.models.MLWorkflow import MLWorkflow\n",
    "from customer_retention_toolkit.api import app\n",
    "\n",
    "# Configure the logger\n",
    "logger = logging.getLogger('example_notebook')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "logger.addHandler(ch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation and Ingestion** (Database)\n",
    "\n",
    "db includes the following:\n",
    "\n",
    "- **schema.py**:  defines the structure of tables and creates them \n",
    "- **sql_interactions**: for all interactions with tables, querries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "db_filename = 'temp.db'\n",
    "\n",
    "if os.path.exists(db_filename):\n",
    "    os.remove(db_filename)\n",
    "    logger.info(f\"Deleted existing {db_filename}\")\n",
    "\n",
    "create_database()\n",
    "InsertToTables()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Includes: \n",
    "- **MLWorkflow.py**: Whole pipeline of ML, including from getting data from db, preprocessing, prediction, adding prediction to db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load data from the database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "dbname = 'temp'\n",
    "workflow = MLWorkflow(dbname)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run the workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "table_names = ['State', 'PlanDetails', 'DayUsage', 'EveUsage', 'NightUsage', 'IntlUsage', 'CustomerMetrics']\n",
    "metrics, X_test, y_test, best_model_predictions = workflow.run_workflow(table_names)\n",
    "\n",
    "logger.info(\"Random Forest Model Metrics:\")\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    logger.info(f\"{metric_name}: {metric_value}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save predictions to the database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "workflow.save_predictions_to_db(X_test, y_test, best_model_predictions, table_name='PredictionResults')    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Example API Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Usage\n",
    "\n",
    "- **api.py**: api functionality such as get_data, create_data, update_data, predict_churn\n",
    "- **run.py**: for starting the api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "import requests\n",
    "\n",
    "# The base URL for your API\n",
    "base_url = \"http://127.0.0.1:5000\"\n",
    "\n",
    "# GET request to the root endpoint\n",
    "response = requests.get(f\"{base_url}/\")\n",
    "print(response.json())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# Replace with a valid customer ID\n",
    "customer_id = 1\n",
    "response = requests.get(f\"{base_url}/get_data/{customer_id}\")\n",
    "print(response.json())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# base_url = 'http://127.0.0.1:5000'  # Replace with the actual base URL if different\n",
    "\n",
    "new_customer_data = {\n",
    "    \"CustomerID\": 2749,\n",
    "    \"ChurnStatus\": 1,\n",
    "    \"StateID\": 1,  # Assuming '1' is a valid StateID in your database\n",
    "    \"PlanID\": 1,  # Assuming '1' is a valid PlanID in your database\n",
    "    \"DayUsageID\": 1,  # Assuming '1' is a valid DayUsageID in your database\n",
    "    \"EveUsageID\": 1,  # Assuming '1' is a valid EveUsageID in your database\n",
    "    \"NightUsageID\": 1,  # Assuming '1' is a valid NightUsageID in your database\n",
    "    \"IntlUsageID\": 1,  # Assuming '1' is a valid IntlUsageID in your database\n",
    "    \"CustomerServiceCalls\": 1  # Number of customer service calls\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{base_url}/create_data\", json=new_customer_data)\n",
    "print(response.json())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# PUT request to update a customer record\n",
    "update_data = {\n",
    "    \"column_name\": \"ChurnStatus\",\n",
    "    \"new_value\": 1,\n",
    "    \"CustomerID\": 2749  # Make sure this ID exists in your database\n",
    "}\n",
    "response = requests.put(f\"{base_url}/update_data\", json=update_data)\n",
    "print(response.json())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# GET request to predict churn for a customer\n",
    "# response = requests.get(f\"{base_url}/predict_churn/{customer_id}\")\n",
    "# print(response.json())\n",
    "customer_id = 555\n",
    "response = requests.get(f\"{base_url}/predict_churn/{customer_id}\")\n",
    "print('Status Code:', response.status_code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "    except JSONDecodeError:\n",
    "        print('Response could not be decoded as JSON:', response.text)\n",
    "else:\n",
    "    print('Failed to fetch data:', response.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
